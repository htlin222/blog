---
title: "從因果推論到傾向分數方法：使用 Python sklearn 實現"
date: "2024-11-04"
author: "林協霆"
template: post
draft: false
description: "這個人很懶不寫介紹"
category: tutorial
---

# 從因果推論到傾向分數方法：使用 Python sklearn 實現

1. 介紹因果推論 (Causal Inference)

因果推論在科學研究和實證研究中扮演了關鍵角色。它是關於確定一個變數（處理或干預）對另一個變數（結果）的因果影響的過程。因果推論的核心問題在於，觀察數據通常不是從隨機實驗中取得，因此存在潛在的偏誤。舉例來說，當研究某種藥物對於疾病的影響時，觀察數據中可能包含處理組和對照組在基線特徵上的系統性差異。這些差異可能會混淆觀察到的效果，導致錯誤的結論。

2. 傾向分數方法概述

傾向分數方法是因果推論中常用的一種工具，用於調整非隨機分派導致的偏誤。傾向分數的定義是給定一組協變數 ￼，某個樣本被分派到處理組的條件概率。簡單來說，傾向分數估算的是每個樣本被分派到處理組的可能性。當傾向分數被正確估算並應用後，處理組和對照組在協變數上的分佈可以達到平衡。

傾向分數的主要應用包括：

    • 傾向分數匹配：根據傾向分數將處理組與對照組進行配對，從而形成平衡的樣本集。
    • 傾向分數加權：使用傾向分數來對樣本加權，以減少樣本間的偏倚。
    • 傾向分數調整：在迴歸模型中將傾向分數作為協變數以調整偏誤。

3. Python 中的實現工具

在 Python 環境中，sklearn 提供了多種工具來幫助研究者實現傾向分數方法。常見的模型如 LogisticRegression 和 RandomForestClassifier 可以用於估算傾向分數。

數據預處理步驟包括：

    1. 數據載入與清洗：確保數據中沒有遺漏值或異常值。
    2. 特徵選擇：選擇合理的協變數來估算傾向分數，避免包含與結果過度相關的變數。

代碼示例展示如何使用 LogisticRegression 來計算傾向分數：

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# 載入數據集

data = pd.read_csv('data.csv')
X = data.drop(columns=['treatment', 'outcome'])
treatment = data['treatment']

# 訓練傾向分數模型

model = LogisticRegression()
model.fit(X, treatment)
propensity_scores = model.predict_proba[X](:, 1)

# 將傾向分數添加到數據集中

data['propensity_score'] = propensity_scores

4. 應用傾向分數於因果分析

傾向分數匹配 是一種將處理組和對照組樣本進行配對的方法，以形成具有相似傾向分數的樣本對。這樣可以在非隨機化的觀察數據中模擬隨機分派的效果。

在 Python 中，雖然沒有內建的 matchit 函式庫，但可以使用 pymatch 等第三方庫或手動實作匹配。例如：

# 使用距離度量進行匹配

matched_pairs = []
for i, score in enumerate(data[data['treatment'] == 1]['propensity_score']):
closest_match = data[data['treatment'] == 0].iloc[(data[data['treatment'] == 0]['propensity_score'] - score).abs().argsort()[:1]]
matched_pairs.append(closest_match)

傾向分數加權 是另一種平衡方法，它通過給樣本分配加權以減少處理組和對照組之間的基線差異。加權方式通常基於逆機率加權（IPW），其權重計算公式如下：

    • 對於處理組： ￼
    • 對於對照組： ￼

可以使用 numpy 計算加權後的樣本權重：

import numpy as np

data['weights'] = np.where(data['treatment'] == 1,
1 / data['propensity_score'],
1 / (1 - data['propensity_score']))

5. 結果解釋與視覺化

視覺化是了解傾向分數方法效果的重要手段。在使用傾向分數匹配或加權後，可以利用直方圖來顯示不同組別間的平衡性。例如，使用 matplotlib 繪製傾向分數的分佈圖：

import matplotlib.pyplot as plt

plt.hist(data[data['treatment'] == 1]['propensity_score'], alpha=0.5, label='Treatment')
plt.hist(data[data['treatment'] == 0]['propensity_score'], alpha=0.5, label='Control')
plt.xlabel('Propensity Score')
plt.ylabel('Frequency')
plt.legend()
plt.title('Distribution of Propensity Scores')
plt.show()

效果估算與置信區間：
在進行傾向分數匹配或加權後，可以利用迴歸模型來估計平均治療效果（ATE）並報告結果。可以進一步使用 statsmodels 中的 OLS 模型來進行迴歸分析。

6. 潛在問題與限制

即使使用了傾向分數方法，研究者仍需注意一些潛在問題：

    • 殘留偏誤：如果協變數中遺漏了重要的混雜變數，則無法完全消除偏誤。
    • 樣本大小的減少：匹配後，樣本數量會減少，可能導致推論效力下降。
    • 變異性增加：加權後的樣本分析可能會導致估計結果變得不穩定，特別是在樣本中出現極端權重的情況下。

7. 結論與延伸閱讀

傾向分數方法是進行非隨機實驗因果推論的有效工具。透過合理的應用，可以減少處理組與對照組間的基線差異並獲得更可靠的效果估計。然而，研究者仍需保持警覺，認識到潛在的偏誤和方法限制。

延伸閱讀：

    • 「Causal Inference for Statistics, Social, and Biomedical Sciences」 by Guido W. Imbens and Donald B. Rubin
    • Python 套件如 causalml 和 pymatch 提供了更進階的功能，適合進一步學習和應用。
